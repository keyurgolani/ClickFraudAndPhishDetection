{"cells":[{"cell_type":"code","source":["from numpy import array\nfrom time import time\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS\nfrom pyspark.mllib.tree import RandomForest\nfrom pyspark.mllib.tree import GradientBoostedTrees"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def parse_interaction(line):\n  print line\n  line_split = line.split(\",\")\n  return LabeledPoint(line_split[1], line_split[2:])"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["input_data = sc.textFile(\"dbfs:/FileStore/tables/7nd94uar1487386945609/merged.csv\")\nheader = input_data.first()\ntrain_data = input_data.filter(lambda x: x != header).map(lambda x: LabeledPoint(x.split(',')[1], x.split(',')[2:])).cache()\ntest_input_data = sc.textFile(\"dbfs:/FileStore/tables/7nd94uar1487386945609/test.csv\")\ntest_data = test_input_data.filter(lambda x: x != header).map(lambda x: LabeledPoint(x.split(',')[1], x.split(',')[2:])).cache()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["logistic_regression_results = []\n\nfor _ in range(10):\n  t0 = time()\n  logistic_model = LogisticRegressionWithLBFGS.train(train_data)\n  trt = time() - t0\n\n  labels_and_preds = test_data.map(lambda p: (p.label, logistic_model.predict(p.features)))\n  t0 = time()\n  fp = float(labels_and_preds.filter(lambda (v, p): p == 1 and v == 0).count())\n  fn = float(labels_and_preds.filter(lambda (v, p): p == 0 and v == 1).count())\n  tp = float(labels_and_preds.filter(lambda (v, p): p == 1 and v == 1).count())\n  tn = float(labels_and_preds.filter(lambda (v, p): p == 0 and v == 0).count())\n\n  test_accuracy = (tp + tn) / (tp + tn + fp + fn)\n  test_recall = tp / (tp + fn)\n  test_precision = tp / (fp + tp)\n  test_f1 = 2 * test_precision * test_recall / (test_precision + test_recall)\n  tst = time() - t0\n  logistic_regression_results.append((round(trt,3), round(tst,3), round(test_accuracy,4), round(test_recall,4), round(test_precision,4), round(test_f1,4)))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["random_forest_results = []\n\nfor _ in range(10):\n  t0 = time()\n  rf_model = RandomForest.trainClassifier(train_data, 2, categoricalFeaturesInfo={40:2, 41:2, 42:2, 43:2, 44:2, 45:2, 46:2, 47:2, 48:2, 49:2}, numTrees=200, featureSubsetStrategy=\"auto\", impurity='gini', maxDepth=10, maxBins=100)\n  trt = time() - t0\n  \n  predictions = rf_model.predict(test_data.map(lambda x: x.features))\n  labelsAndPredictions = test_data.map(lambda lp: lp.label).zip(predictions)\n  \n  t0 = time()\n  fp = float(labelsAndPredictions.filter(lambda (v, p): p == 1 and v == 0).count())\n  fn = float(labelsAndPredictions.filter(lambda (v, p): p == 0 and v == 1).count())\n  tp = float(labelsAndPredictions.filter(lambda (v, p): p == 1 and v == 1).count())\n  tn = float(labelsAndPredictions.filter(lambda (v, p): p == 0 and v == 0).count())\n\n  test_accuracy = (tp + tn) / (tp + tn + fp + fn)\n  test_recall = tp / (tp + fn)\n  test_precision = tp / (fp + tp)\n  test_f1 = 2 * test_precision * test_recall / (test_precision + test_recall)\n  tst = time() - t0\n  random_forest_results.append((round(trt,3), round(tst,3), round(test_accuracy,4), round(test_recall,4), round(test_precision,4), round(test_f1,4)))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["gradient_boosted_trees_results = []\nfor _ in range(10):\n  t0 = time()\n  gbt_model = GradientBoostedTrees.trainClassifier(train_data, categoricalFeaturesInfo={40:2, 41:2, 42:2, 43:2, 44:2, 45:2, 46:2, 47:2, 48:2, 49:2}, numIterations=3)\n  trt = time() - t0\n  \n  predictions = gbt_model.predict(test_data.map(lambda x: x.features))\n  labelsAndPredictions = test_data.map(lambda lp: lp.label).zip(predictions)\n  \n  t0 = time()\n  fp = float(labelsAndPredictions.filter(lambda (v, p): p == 1 and v == 0).count())\n  fn = float(labelsAndPredictions.filter(lambda (v, p): p == 0 and v == 1).count())\n  tp = float(labelsAndPredictions.filter(lambda (v, p): p == 1 and v == 1).count())\n  tn = float(labelsAndPredictions.filter(lambda (v, p): p == 0 and v == 0).count())\n\n  test_accuracy = (tp + tn) / (tp + tn + fp + fn)\n  test_recall = tp / (tp + fn)\n  test_precision = tp / (fp + tp)\n  test_f1 = 2 * test_precision * test_recall / (test_precision + test_recall)\n  tst = time() - t0\n  gradient_boosted_trees_results.append((round(trt,3), round(tst,3), round(test_accuracy,4), round(test_recall,4), round(test_precision,4), round(test_f1,4)))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["print display(logistic_regression_results)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["print display(random_forest_results)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["print display(gradient_boosted_trees_results)"],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"ClickFraud","notebookId":3895861801834410},"nbformat":4,"nbformat_minor":0}
