{"cells":[{"cell_type":"code","source":["data = [1, 2, 3, 4, 5]\nprint data\nrdd = sc.parallelize(data, 4)\nprint rdd.collect()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["data = [1, 3, 2, 2, 5, 1, 2, 4, 3, 1]\nprint data\n# Remember: Out of space transformation.\n# Returns a new RDD does not make changes in the same RDD.\n# The returned value needs to be assigned to a variable to be accessed.\nrdd = sc.parallelize(data, 4)\nprint rdd.map(lambda x : x * 2).collect()\nprint rdd.filter(lambda x : x % 2 == 0).collect()\nprint rdd.distinct().collect()\nprint rdd.map(lambda x : [x, x**2]).collect()\nprint rdd.flatMap(lambda x : [x, x**2]).collect()\nprint rdd.reduce(lambda a,b : a * b)\nprint rdd.take(4)\nprint rdd.takeOrdered(10)\nprint rdd.takeOrdered(15)\nprint rdd.takeOrdered(10, key=lambda s : s * -1)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%fs ls /databricks-datasets/samples/docs/"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["distFile = sc.textFile(\"/databricks-datasets/samples/docs/README.md\", 4)\nprint distFile.count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data = [(1, 3), (2, 5), (1, 2), (4, 5), (2, 4), (3, 6), (9, 5), (1, 1)]\nrdd = sc.parallelize(data)\nprint rdd.reduceByKey(lambda a, b : a + b).collect()\nprint rdd.sortByKey().collect()\nprint rdd.groupByKey().collect()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Broadcast Variables\nbcVar = sc.broadcast([1, 2, 3])\nprint bcVar.value"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Accumulators\naccVar = sc.accumulator(0)\nrdd = sc.parallelize([1,2,3,4,5])\ndef foo(x):\n  global accVar\n  accVar += x\n  \nrdd.foreach(foo)\n\nprint accVar.value"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["rdd = sc.textFile(\"/databricks-datasets/samples/docs/README.md\", 4)\nblankLines = sc.accumulator(0)\n\ndef extractWords(line):\n  global blankLines\n  if line == \"\":\n    blankLines += 1\n    return []\n  else:\n      return line.split(\" \")\n\nwords = rdd.flatMap(extractWords).filter(lambda x : x != '').takeOrdered(rdd.count())\nprint \"\"\"\n~~~Words~~~\n{}\"\"\".format(words)\nprint \"Number of blank lines is {}\".format(blankLines)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["import re\n\ndef wordCount(wordListRDD):\n    \"\"\"Creates a pair RDD with word counts from an RDD of words.\n\n    Args:\n        wordListRDD (RDD of str): An RDD consisting of words.\n\n    Returns:\n        RDD of (str, int): An RDD consisting of (word, count) tuples.\n    \"\"\"\n    return wordListRDD.map(lambda x : (x, 1)).reduceByKey(lambda x, y : x + y)\n\n\ndef removePunctuation(text):\n    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n\n    Note:\n        Only spaces, letters, and numbers should be retained.  Other characters should should be\n        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n        punctuation is removed.\n\n    Args:\n        text (str): A string.\n\n    Returns:\n        str: The cleaned up string.\n    \"\"\"\n    textWords = re.sub(r'[^\\w\\s]|[_,!.\\']','',text.lower().strip())\n    return textWords\n\n\nshakespeareRDD = (sc\n                  .textFile(\"/databricks-datasets/samples/docs/README.md\", 8)\n                  .map(removePunctuation))\nshakespeareWordsRDD = shakespeareRDD.flatMap(lambda x : x.split())\nshakeWordsRDD = shakespeareWordsRDD.filter(lambda x : x != '')\ntop15WordsAndCounts = wordCount(shakeWordsRDD).takeOrdered(15, key=lambda x : -x[1])\nprint '\\n'.join(map(lambda (w, c): '{0}: {1}'.format(w, c), top15WordsAndCounts))"],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"SparkPython","notebookId":1926928631715382},"nbformat":4,"nbformat_minor":0}
